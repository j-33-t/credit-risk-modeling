{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state: UT</th>\n",
       "      <th>addr_state: VA</th>\n",
       "      <th>addr_state: VT</th>\n",
       "      <th>addr_state: WA</th>\n",
       "      <th>addr_state: WI</th>\n",
       "      <th>addr_state: WV</th>\n",
       "      <th>addr_state: WY</th>\n",
       "      <th>initial_list_status: f</th>\n",
       "      <th>initial_list_status: w</th>\n",
       "      <th>good_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975</td>\n",
       "      <td>36 months</td>\n",
       "      <td>11</td>\n",
       "      <td>163</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>36 months</td>\n",
       "      <td>16</td>\n",
       "      <td>84</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13</td>\n",
       "      <td>339</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>13</td>\n",
       "      <td>68</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501    1296599       5000         5000             4975   36 months   \n",
       "1  1077430    1314167       2500         2500             2500   60 months   \n",
       "2  1077175    1313524       2400         2400             2400   36 months   \n",
       "3  1076863    1277178      10000        10000            10000   36 months   \n",
       "4  1075358    1311748       3000         3000             3000   60 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade  ... addr_state: UT addr_state: VA  \\\n",
       "0        11          163     B        B2  ...          False          False   \n",
       "1        15           60     C        C4  ...          False          False   \n",
       "2        16           84     C        C5  ...          False          False   \n",
       "3        13          339     C        C1  ...          False          False   \n",
       "4        13           68     B        B5  ...          False          False   \n",
       "\n",
       "  addr_state: VT  addr_state: WA addr_state: WI addr_state: WV addr_state: WY  \\\n",
       "0          False           False          False          False          False   \n",
       "1          False           False          False          False          False   \n",
       "2          False           False          False          False          False   \n",
       "3          False           False          False          False          False   \n",
       "4          False           False          False          False          False   \n",
       "\n",
       "  initial_list_status: f initial_list_status: w good_bad  \n",
       "0                   True                  False        1  \n",
       "1                   True                  False        0  \n",
       "2                   True                  False        1  \n",
       "3                   True                  False        1  \n",
       "4                   True                  False        1  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data = pd.read_pickle(\"../loan_data_defaultDefinition.pkl\")\n",
    "loan_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Splitting dataset into test and training respectively \n",
    " - We split two dataframes with inputs and targets, each into a train and test dataframe, and store them in variables\n",
    " - Takes a set of inputs and a set of targets as arguments. Splits the inputs and the targets into four dataframes:\n",
    " - Inputs - Train, Inputs - Test, Targets - Train, Targets - Test.\n",
    " - We set the size of the test dataset to be 20%.\n",
    " - Respectively, the size of the train dataset becomes 80%.\n",
    " - We also set a specific random state for reproducibility just as setting seed.\n",
    " - This would allow us to perform the exact same split multimple times.\n",
    " - This means, to assign the exact same observations to the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_train, loan_data_inputs_test, loan_data_targets_train, loan_data_targets_test = train_test_split(loan_data.drop('good_bad', axis = 1), loan_data['good_bad'],test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is the output for the shape of dataframe (rows,columns) \n",
      "\n",
      "Training dataset with explanatory variables : (373028, 205) \n",
      "\n",
      "Training dataset with target variable : (373028,) \n",
      "\n",
      "Testing dataset with explanatory variables : (93257, 205) \n",
      "\n",
      "Testing dataset with target variable :(93257,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The following is the output for the shape of dataframe (rows,columns) \\n\")\n",
    "\n",
    "print(f\"Training dataset with explanatory variables : {loan_data_inputs_train.shape} \\n\")\n",
    "# Displays the size of the dataframe.\n",
    "print(f\"Training dataset with target variable : {loan_data_targets_train.shape} \\n\")\n",
    "# Displays the size of the dataframe.\n",
    "print(f\"Testing dataset with explanatory variables : {loan_data_inputs_test.shape} \\n\")\n",
    "# Displays the size of the dataframe.\n",
    "print(f\"Testing dataset with target variable :{loan_data_targets_test.shape} \\n\")\n",
    "# Displays the size of the dataframe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy datasets for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_prepr = loan_data_inputs_test\n",
    "df_targets_prepr = loan_data_targets_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing Discrete Variables : Creating Dummy Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Variable : Grade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the worst category as a Reference category. \n",
    "\n",
    "- Hence, here for variable **GRADE** we will keep **G** as reference category. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Variable: home_ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many categories with very few observations and many categories with very different \"good\" %.\n",
    "# Therefore, we create a new discrete variable where we combine some of the categories.\n",
    "# 'OTHERS' and 'NONE' are riskiest but are very few. 'RENT' is the next riskiest.\n",
    "# 'ANY' are least risky but are too few. Conceptually, they belong to the same category. Also, their inclusion would not change anything.\n",
    "# We combine them in one category, 'RENT_OTHER_NONE_ANY'.\n",
    "# We end up with 3 categories: 'RENT_OTHER_NONE_ANY', 'OWN', 'MORTGAGE'.\n",
    "df_inputs_prepr['home_ownership:RENT_OTHER_NONE_ANY'] = sum([df_inputs_prepr['home_ownership: RENT'], df_inputs_prepr['home_ownership: OTHER'],\n",
    "                                                      df_inputs_prepr['home_ownership: NONE'],df_inputs_prepr['home_ownership: ANY']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'RENT_OTHER_NONE_ANY' will be the reference category.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variable: addr_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'IN', 'AZ', 'MI', 'PA', 'MO', 'CT', 'IL', 'SC', 'VA', 'NY',\n",
       "       'FL', 'TX', 'NC', 'NM', 'NJ', 'KY', 'DE', 'OK', 'CO', 'OH', 'GA',\n",
       "       'LA', 'WA', 'AL', 'TN', 'MD', 'NV', 'MN', 'RI', 'NH', 'MA', 'MS',\n",
       "       'UT', 'WV', 'HI', 'KS', 'OR', 'WY', 'WI', 'AK', 'DC', 'AR', 'MT',\n",
       "       'SD', 'VT', 'IA', 'ID', 'ME', 'NE'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['addr_state'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "North Dakota [ND] is missing from the addr_state list so we will add it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ['addr_state: ND'] in df_inputs_prepr.columns.values:\n",
    "    pass\n",
    "else:\n",
    "    df_inputs_prepr['addr_state: ND'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following categories:\n",
    "# 'ND' 'NE' 'IA' NV' 'FL' 'HI' 'AL'\n",
    "# 'NM' 'VA'\n",
    "# 'NY'\n",
    "# 'OK' 'TN' 'MO' 'LA' 'MD' 'NC'\n",
    "# 'CA'\n",
    "# 'UT' 'KY' 'AZ' 'NJ'\n",
    "# 'AR' 'MI' 'PA' 'OH' 'MN'\n",
    "# 'RI' 'MA' 'DE' 'SD' 'IN'\n",
    "# 'GA' 'WA' 'OR'\n",
    "# 'WI' 'MT'\n",
    "# 'TX'\n",
    "# 'IL' 'CT'\n",
    "# 'KS' 'SC' 'CO' 'VT' 'AK' 'MS'\n",
    "# 'WV' 'NH' 'WY' 'DC' 'ME' 'ID'\n",
    "\n",
    "# 'IA_NV_HI_ID_AL_FL' will be the reference category.\n",
    "df_inputs_prepr['addr_state:ND_NE_IA_NV_FL_HI_AL'] = sum([df_inputs_prepr['addr_state: ND'], df_inputs_prepr['addr_state: NE'],\n",
    "                                              df_inputs_prepr['addr_state: IA'], df_inputs_prepr['addr_state: NV'],\n",
    "                                              df_inputs_prepr['addr_state: FL'], df_inputs_prepr['addr_state: HI'],\n",
    "                                                          df_inputs_prepr['addr_state: AL']])\n",
    "\n",
    "df_inputs_prepr['addr_state:NM_VA'] = sum([df_inputs_prepr['addr_state: NM'], df_inputs_prepr['addr_state: VA']])\n",
    "\n",
    "df_inputs_prepr['addr_state:OK_TN_MO_LA_MD_NC'] = sum([df_inputs_prepr['addr_state: OK'], df_inputs_prepr['addr_state: TN'],\n",
    "                                              df_inputs_prepr['addr_state: MO'], df_inputs_prepr['addr_state: LA'],\n",
    "                                              df_inputs_prepr['addr_state: MD'], df_inputs_prepr['addr_state: NC']])\n",
    "\n",
    "df_inputs_prepr['addr_state:UT_KY_AZ_NJ'] = sum([df_inputs_prepr['addr_state: UT'], df_inputs_prepr['addr_state: KY'],\n",
    "                                              df_inputs_prepr['addr_state: AZ'], df_inputs_prepr['addr_state: NJ']])\n",
    "\n",
    "df_inputs_prepr['addr_state:AR_MI_PA_OH_MN'] = sum([df_inputs_prepr['addr_state: AR'], df_inputs_prepr['addr_state: MI'],\n",
    "                                              df_inputs_prepr['addr_state: PA'], df_inputs_prepr['addr_state: OH'],\n",
    "                                              df_inputs_prepr['addr_state: MN']])\n",
    "\n",
    "df_inputs_prepr['addr_state:RI_MA_DE_SD_IN'] = sum([df_inputs_prepr['addr_state: RI'], df_inputs_prepr['addr_state: MA'],\n",
    "                                              df_inputs_prepr['addr_state: DE'], df_inputs_prepr['addr_state: SD'],\n",
    "                                              df_inputs_prepr['addr_state: IN']])\n",
    "\n",
    "df_inputs_prepr['addr_state:GA_WA_OR'] = sum([df_inputs_prepr['addr_state: GA'], df_inputs_prepr['addr_state: WA'],\n",
    "                                              df_inputs_prepr['addr_state: OR']])\n",
    "\n",
    "df_inputs_prepr['addr_state:WI_MT'] = sum([df_inputs_prepr['addr_state: WI'], df_inputs_prepr['addr_state: MT']])\n",
    "\n",
    "df_inputs_prepr['addr_state:IL_CT'] = sum([df_inputs_prepr['addr_state: IL'], df_inputs_prepr['addr_state: CT']])\n",
    "\n",
    "df_inputs_prepr['addr_state:KS_SC_CO_VT_AK_MS'] = sum([df_inputs_prepr['addr_state: KS'], df_inputs_prepr['addr_state: SC'],\n",
    "                                              df_inputs_prepr['addr_state: CO'], df_inputs_prepr['addr_state: VT'],\n",
    "                                              df_inputs_prepr['addr_state: AK'], df_inputs_prepr['addr_state: MS']])\n",
    "\n",
    "df_inputs_prepr['addr_state:WV_NH_WY_DC_ME_ID'] = sum([df_inputs_prepr['addr_state: WV'], df_inputs_prepr['addr_state: NH'],\n",
    "                                              df_inputs_prepr['addr_state: WY'], df_inputs_prepr['addr_state: DC'],\n",
    "                                              df_inputs_prepr['addr_state: ME'], df_inputs_prepr['addr_state: ID']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'IA_NV_HI_ID_AL_FL' will be the reference category"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Variable: Verfification Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Verified', 'Source Verified', 'Not Verified'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['verification_status'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verified will be the reference category"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Variable: Purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['home_improvement', 'credit_card', 'debt_consolidation',\n",
       "       'vacation', 'house', 'medical', 'small_business', 'car', 'other',\n",
       "       'major_purchase', 'wedding', 'moving', 'educational',\n",
       "       'renewable_energy'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['purpose'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We combine 'educational', 'small_business', 'wedding', 'renewable_energy', 'moving', 'house' in one category: 'educ__sm_b__wedd__ren_en__mov__house'.\n",
    "# We combine 'other', 'medical', 'vacation' in one category: 'oth__med__vacation'.\n",
    "# We combine 'major_purchase', 'car', 'home_improvement' in one category: 'major_purch__car__home_impr'.\n",
    "# We leave 'debt_consolidtion' in a separate category.\n",
    "# We leave 'credit_card' in a separate category.\n",
    "# 'educ__sm_b__wedd__ren_en__mov__house' will be the reference category.\n",
    "df_inputs_prepr['purpose: educ__sm_b__wedd__ren_en__mov__house'] = sum([df_inputs_prepr['purpose: educational'], df_inputs_prepr['purpose: small_business'],\n",
    "                                                                 df_inputs_prepr['purpose: wedding'], df_inputs_prepr['purpose: renewable_energy'],\n",
    "                                                                 df_inputs_prepr['purpose: moving'], df_inputs_prepr['purpose: house']])\n",
    "df_inputs_prepr['purpose: oth__med__vacation'] = sum([df_inputs_prepr['purpose: other'], df_inputs_prepr['purpose: medical'],\n",
    "                                             df_inputs_prepr['purpose: vacation']])\n",
    "df_inputs_prepr['purpose: major_purch__car__home_impr'] = sum([df_inputs_prepr['purpose: major_purchase'], df_inputs_prepr['purpose: car'],\n",
    "                                                        df_inputs_prepr['purpose: home_improvement']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'educ__sm_b__wedd__ren_en__mov__house' will be the reference category."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Variable: Initial list status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['f', 'w'], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['initial_list_status'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Continous Variables : Create Dummy Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Variable : Term_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60, 36])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term\n",
    "df_inputs_prepr['term_int'].unique()\n",
    "# There are only two unique values, 36 and 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave as is.\n",
    "# '60' will be the reference category.\n",
    "df_inputs_prepr['term:36'] = np.where((df_inputs_prepr['term_int'] == 36), 1, 0)\n",
    "df_inputs_prepr['term:60'] = np.where((df_inputs_prepr['term_int'] == 60), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Variable: emp_length_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 10,  1,  2,  9,  3,  6,  4,  7,  8,  5])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emp_length_int\n",
    "df_inputs_prepr['emp_length_int'].unique()\n",
    "# Has only 11 levels: from 0 to 10. Hence, we turn it into a factor with 11 levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following categories: '0', '1', '2 - 4', '5 - 6', '7 - 9', '10'\n",
    "# '0' will be the reference category\n",
    "df_inputs_prepr['emp_length:0'] = np.where(df_inputs_prepr['emp_length_int'].isin([0]), 1, 0)\n",
    "df_inputs_prepr['emp_length:1'] = np.where(df_inputs_prepr['emp_length_int'].isin([1]), 1, 0)\n",
    "df_inputs_prepr['emp_length:2-4'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(2, 5)), 1, 0)\n",
    "df_inputs_prepr['emp_length:5-6'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(5, 7)), 1, 0)\n",
    "df_inputs_prepr['emp_length:7-9'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(7, 10)), 1, 0)\n",
    "df_inputs_prepr['emp_length:10'] = np.where(df_inputs_prepr['emp_length_int'].isin([10]), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variable: mnths_since_issue_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40.,  37.,  65.,  36.,  57.,  49.,  84.,  50.,  47.,  58.,  71.,\n",
       "        76.,  46.,  45.,  55.,  54., 117.,  62., 100.,  38.,  52.,  39.,\n",
       "        51.,  42.,  48.,  56.,  44.,  35.,  53.,  73.,  43.,  72., 101.,\n",
       "        69.,  93.,  87.,  67.,  80.,  70.,  75., 102.,  64.,  79.,  89.,\n",
       "        74.,  66.,  41.,  60.,  63.,  59.,  83.,  86., 108.,  94.,  77.,\n",
       "        81.,  68.,  88.,  61., 106.,  78.,  90., 116.,  97., 113.,  95.,\n",
       "       112., 114.,  98.,  91., 115., 104., 122.,  99., 123.,  85.,  82.,\n",
       "        92., 103., 107.,  96., 105., 110., 111., 120., 109., 118., 119.,\n",
       "       121., 124.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['mths_since_issue_d'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_prepr['mths_since_issue_d_factor'] = pd.cut(df_inputs_prepr['mths_since_issue_d'], 50)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362514     (38.56, 40.34]\n",
       "288564     (36.78, 38.56]\n",
       "213591     (63.48, 65.26]\n",
       "263083    (34.911, 36.78]\n",
       "165001     (56.36, 58.14]\n",
       "               ...       \n",
       "115         (70.6, 72.38]\n",
       "296284     (36.78, 38.56]\n",
       "61777      (47.46, 49.24]\n",
       "91763      (49.24, 51.02]\n",
       "167512     (56.36, 58.14]\n",
       "Name: mths_since_issue_d_factor, Length: 93257, dtype: category\n",
       "Categories (50, interval[float64, right]): [(34.911, 36.78] < (36.78, 38.56] < (38.56, 40.34] < (40.34, 42.12] ... (116.88, 118.66] < (118.66, 120.44] < (120.44, 122.22] < (122.22, 124.0]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['mths_since_issue_d_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following categories:\n",
    "# < 38, 38 - 39, 40 - 41, 42 - 48, 49 - 52, 53 - 64, 65 - 84, > 84.\n",
    "df_inputs_prepr['mths_since_issue_d:<38'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(38)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:38-39'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(38, 40)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:40-41'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(40, 42)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:42-48'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(42, 49)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:49-52'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(49, 53)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:53-64'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(53, 65)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:65-84'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(65, 85)), 1, 0)\n",
    "df_inputs_prepr['mths_since_issue_d:>84'] = np.where(df_inputs_prepr['mths_since_issue_d'].isin(range(85, int(df_inputs_prepr['mths_since_issue_d'].max()))), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Variable: int_rate_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_rate\n",
    "df_inputs_prepr['int_rate_factor'] = pd.cut(df_inputs_prepr['int_rate'], 50)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '< 9.548', '9.548 - 12.025', '12.025 - 15.74', '15.74 - 20.281', '> 20.281'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_prepr['int_rate:<9.548'] = np.where((df_inputs_prepr['int_rate'] <= 9.548), 1, 0)\n",
    "df_inputs_prepr['int_rate:9.548-12.025'] = np.where((df_inputs_prepr['int_rate'] > 9.548) & (df_inputs_prepr['int_rate'] <= 12.025), 1, 0)\n",
    "df_inputs_prepr['int_rate:12.025-15.74'] = np.where((df_inputs_prepr['int_rate'] > 12.025) & (df_inputs_prepr['int_rate'] <= 15.74), 1, 0)\n",
    "df_inputs_prepr['int_rate:15.74-20.281'] = np.where((df_inputs_prepr['int_rate'] > 15.74) & (df_inputs_prepr['int_rate'] <= 20.281), 1, 0)\n",
    "df_inputs_prepr['int_rate:>20.281'] = np.where((df_inputs_prepr['int_rate'] > 20.281), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Variable: funded_amnt_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   93257\n",
       "mean    14290\n",
       "std      8270\n",
       "min       500\n",
       "25%      8000\n",
       "50%     12000\n",
       "75%     20000\n",
       "max     35000\n",
       "Name: funded_amnt, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['funded_amnt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funded_amnt\n",
    "df_inputs_prepr['funded_amnt_factor'] = pd.cut(df_inputs_prepr['funded_amnt'], 50)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Variable: mths_since_earliest_cr_line_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   93257\n",
       "mean      238\n",
       "std        85\n",
       "min         0\n",
       "25%       181\n",
       "50%       222\n",
       "75%       281\n",
       "max       789\n",
       "Name: mnths_since_earliest_cr_line, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['mnths_since_earliest_cr_line'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_earliest_cr_line\n",
    "df_inputs_prepr['mths_since_earliest_cr_line_factor'] = pd.cut(df_inputs_prepr['mnths_since_earliest_cr_line'], 50)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the following categories:\n",
    "# < 140, # 141 - 164, # 165 - 247, # 248 - 270, # 271 - 352, # > 352\n",
    "df_inputs_prepr['mnths_since_earliest_cr_line:<140'] = np.where(df_inputs_prepr['mnths_since_earliest_cr_line'].isin(range(140)), 1, 0)\n",
    "df_inputs_prepr['mnths_since_earliest_cr_line:141-164'] = np.where(df_inputs_prepr['mnths_since_earliest_cr_line'].isin(range(140, 165)), 1, 0)\n",
    "df_inputs_prepr['mnths_since_earliest_cr_line:165-247'] = np.where(df_inputs_prepr['mnths_since_earliest_cr_line'].isin(range(165, 248)), 1, 0)\n",
    "df_inputs_prepr['mnths_since_earliest_cr_line:248-270'] = np.where(df_inputs_prepr['mnths_since_earliest_cr_line'].isin(range(248, 271)), 1, 0)\n",
    "df_inputs_prepr['mnths_since_earliest_cr_line:271-352'] = np.where(df_inputs_prepr['mnths_since_earliest_cr_line'].isin(range(271, 353)), 1, 0)\n",
    "df_inputs_prepr['mnths_since_earliest_cr_line:>352'] = np.where(df_inputs_prepr['mnths_since_earliest_cr_line'].isin(range(353, int(df_inputs_prepr['mnths_since_earliest_cr_line'].max()))), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Variable: delinq_2yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   93257\n",
       "mean        0\n",
       "std         1\n",
       "min         0\n",
       "25%         0\n",
       "50%         0\n",
       "75%         0\n",
       "max        19\n",
       "Name: delinq_2yrs, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['delinq_2yrs'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories: 0, 1-3, >=4\n",
    "df_inputs_prepr['delinq_2yrs:0'] = np.where((df_inputs_prepr['delinq_2yrs'] == 0), 1, 0)\n",
    "df_inputs_prepr['delinq_2yrs:1-3'] = np.where((df_inputs_prepr['delinq_2yrs'] >= 1) & (df_inputs_prepr['delinq_2yrs'] <= 3), 1, 0)\n",
    "df_inputs_prepr['delinq_2yrs:>=4'] = np.where((df_inputs_prepr['delinq_2yrs'] >= 9), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 . Variable: inq_last_6mnths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   93257\n",
       "mean        1\n",
       "std         1\n",
       "min         0\n",
       "25%         0\n",
       "50%         0\n",
       "75%         1\n",
       "max        24\n",
       "Name: inq_last_6mths, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['inq_last_6mths'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories: 0, 1 - 2, 3 - 6, > 6\n",
    "df_inputs_prepr['inq_last_6mths:0'] = np.where((df_inputs_prepr['inq_last_6mths'] == 0), 1, 0)\n",
    "df_inputs_prepr['inq_last_6mths:1-2'] = np.where((df_inputs_prepr['inq_last_6mths'] >= 1) & (df_inputs_prepr['inq_last_6mths'] <= 2), 1, 0)\n",
    "df_inputs_prepr['inq_last_6mths:3-6'] = np.where((df_inputs_prepr['inq_last_6mths'] >= 3) & (df_inputs_prepr['inq_last_6mths'] <= 6), 1, 0)\n",
    "df_inputs_prepr['inq_last_6mths:>6'] = np.where((df_inputs_prepr['inq_last_6mths'] > 6), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Variable: open_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   93257\n",
       "mean       11\n",
       "std         5\n",
       "min         0\n",
       "25%         8\n",
       "50%        10\n",
       "75%        14\n",
       "max        61\n",
       "Name: open_acc, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['open_acc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories: '0', '1-3', '4-12', '13-17', '18-22', '23-25', '26-30', '>30'\n",
    "df_inputs_prepr['open_acc:0'] = np.where((df_inputs_prepr['open_acc'] == 0), 1, 0)\n",
    "df_inputs_prepr['open_acc:1-3'] = np.where((df_inputs_prepr['open_acc'] >= 1) & (df_inputs_prepr['open_acc'] <= 3), 1, 0)\n",
    "df_inputs_prepr['open_acc:4-12'] = np.where((df_inputs_prepr['open_acc'] >= 4) & (df_inputs_prepr['open_acc'] <= 12), 1, 0)\n",
    "df_inputs_prepr['open_acc:13-17'] = np.where((df_inputs_prepr['open_acc'] >= 13) & (df_inputs_prepr['open_acc'] <= 17), 1, 0)\n",
    "df_inputs_prepr['open_acc:18-22'] = np.where((df_inputs_prepr['open_acc'] >= 18) & (df_inputs_prepr['open_acc'] <= 22), 1, 0)\n",
    "df_inputs_prepr['open_acc:23-25'] = np.where((df_inputs_prepr['open_acc'] >= 23) & (df_inputs_prepr['open_acc'] <= 25), 1, 0)\n",
    "df_inputs_prepr['open_acc:26-30'] = np.where((df_inputs_prepr['open_acc'] >= 26) & (df_inputs_prepr['open_acc'] <= 30), 1, 0)\n",
    "df_inputs_prepr['open_acc:>=31'] = np.where((df_inputs_prepr['open_acc'] >= 31), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Variable: pub_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   93257\n",
       "mean        0\n",
       "std         1\n",
       "min         0\n",
       "25%         0\n",
       "50%         0\n",
       "75%         0\n",
       "max        49\n",
       "Name: pub_rec, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['pub_rec'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories '0-2', '3-4', '>=5'\n",
    "df_inputs_prepr['pub_rec:0-2'] = np.where((df_inputs_prepr['pub_rec'] >= 0) & (df_inputs_prepr['pub_rec'] <= 2), 1, 0)\n",
    "df_inputs_prepr['pub_rec:3-4'] = np.where((df_inputs_prepr['pub_rec'] >= 3) & (df_inputs_prepr['pub_rec'] <= 4), 1, 0)\n",
    "df_inputs_prepr['pub_rec:>=5'] = np.where((df_inputs_prepr['pub_rec'] >= 5), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Variable: total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   93257\n",
       "mean       25\n",
       "std        12\n",
       "min         0\n",
       "25%        17\n",
       "50%        23\n",
       "75%        32\n",
       "max       156\n",
       "Name: total_acc, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['total_acc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_acc\n",
    "df_inputs_prepr['total_acc_factor'] = pd.cut(df_inputs_prepr['total_acc'], 50)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories: '<=27', '28-51', '>51'\n",
    "df_inputs_prepr['total_acc:<=27'] = np.where((df_inputs_prepr['total_acc'] <= 27), 1, 0)\n",
    "df_inputs_prepr['total_acc:28-51'] = np.where((df_inputs_prepr['total_acc'] >= 28) & (df_inputs_prepr['total_acc'] <= 51), 1, 0)\n",
    "df_inputs_prepr['total_acc:>=52'] = np.where((df_inputs_prepr['total_acc'] >= 52), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Variable: acc_now_delinq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['acc_now_delinq'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories: '0', '>=1'\n",
    "df_inputs_prepr['acc_now_delinq:0'] = np.where((df_inputs_prepr['acc_now_delinq'] == 0), 1, 0)\n",
    "df_inputs_prepr['acc_now_delinq:>=1'] = np.where((df_inputs_prepr['acc_now_delinq'] >= 1), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable 13: total_rev_hi_lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     93257\n",
       "mean      27586\n",
       "std       29391\n",
       "min           0\n",
       "25%       11500\n",
       "50%       20100\n",
       "75%       34500\n",
       "max     2013133\n",
       "Name: total_rev_hi_lim, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.0f}'.format)\n",
    "df_inputs_prepr['total_rev_hi_lim'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_rev_hi_lim\n",
    "df_inputs_prepr['total_rev_hi_lim_factor'] = pd.cut(df_inputs_prepr['total_rev_hi_lim'], 2000)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 2000 categories by its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/429332966.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['total_rev_hi_lim:55K-95K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 55000) & (df_inputs_prepr['total_rev_hi_lim'] <= 95000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/429332966.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['total_rev_hi_lim:>95K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 95000), 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# Categories\n",
    "# '<=5K', '5K-10K', '10K-20K', '20K-30K', '30K-40K', '40K-55K', '55K-95K', '>95K'\n",
    "df_inputs_prepr['total_rev_hi_lim:<=5K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] <= 5000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:5K-10K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 5000) & (df_inputs_prepr['total_rev_hi_lim'] <= 10000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:10K-20K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 10000) & (df_inputs_prepr['total_rev_hi_lim'] <= 20000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:20K-30K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 20000) & (df_inputs_prepr['total_rev_hi_lim'] <= 30000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:30K-40K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 30000) & (df_inputs_prepr['total_rev_hi_lim'] <= 40000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:40K-55K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 40000) & (df_inputs_prepr['total_rev_hi_lim'] <= 55000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:55K-95K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 55000) & (df_inputs_prepr['total_rev_hi_lim'] <= 95000), 1, 0)\n",
    "df_inputs_prepr['total_rev_hi_lim:>95K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 95000), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Variable : installment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   93257\n",
       "mean      432\n",
       "std       243\n",
       "min        16\n",
       "25%       257\n",
       "50%       380\n",
       "75%       567\n",
       "max      1407\n",
       "Name: installment, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['installment'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/1980375069.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['installment_factor'] = pd.cut(df_inputs_prepr['installment'], 50)\n"
     ]
    }
   ],
   "source": [
    "# installment\n",
    "df_inputs_prepr['installment_factor'] = pd.cut(df_inputs_prepr['installment'], 50)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. annual_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     93257\n",
       "mean      73492\n",
       "std       59788\n",
       "min        4800\n",
       "25%       45000\n",
       "50%       63000\n",
       "75%       89000\n",
       "max     7500000\n",
       "Name: annual_inc, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['annual_inc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3969872777.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc_factor'] = pd.cut(df_inputs_prepr['annual_inc'], 50)\n"
     ]
    }
   ],
   "source": [
    "# annual_inc\n",
    "df_inputs_prepr['annual_inc_factor'] = pd.cut(df_inputs_prepr['annual_inc'], 50)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_prepr['annual_inc_factor'] = pd.cut(df_inputs_prepr['annual_inc'], 100)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 100 categories by its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial examination shows that there are too few individuals with large income and too many with small income.\n",
    "# Hence, we are going to have one category for more than 150K, and we are going to apply our approach to determine\n",
    "# the categories of everyone with 140k or less.\n",
    "df_inputs_prepr_temp = df_inputs_prepr.loc[df_inputs_prepr['annual_inc'] <= 140000, : ]\n",
    "#loan_data_temp = loan_data_temp.reset_index(drop = True)\n",
    "#df_inputs_prepr_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3264365375.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_inputs_prepr_temp[\"annual_inc_factor\"] = pd.cut(df_inputs_prepr_temp['annual_inc'], 50)\n"
     ]
    }
   ],
   "source": [
    "df_inputs_prepr_temp[\"annual_inc_factor\"] = pd.cut(df_inputs_prepr_temp['annual_inc'], 50)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:<20K'] = np.where((df_inputs_prepr['annual_inc'] <= 20000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:20K-30K'] = np.where((df_inputs_prepr['annual_inc'] > 20000) & (df_inputs_prepr['annual_inc'] <= 30000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:30K-40K'] = np.where((df_inputs_prepr['annual_inc'] > 30000) & (df_inputs_prepr['annual_inc'] <= 40000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:40K-50K'] = np.where((df_inputs_prepr['annual_inc'] > 40000) & (df_inputs_prepr['annual_inc'] <= 50000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:50K-60K'] = np.where((df_inputs_prepr['annual_inc'] > 50000) & (df_inputs_prepr['annual_inc'] <= 60000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:60K-70K'] = np.where((df_inputs_prepr['annual_inc'] > 60000) & (df_inputs_prepr['annual_inc'] <= 70000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:70K-80K'] = np.where((df_inputs_prepr['annual_inc'] > 70000) & (df_inputs_prepr['annual_inc'] <= 80000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:80K-90K'] = np.where((df_inputs_prepr['annual_inc'] > 80000) & (df_inputs_prepr['annual_inc'] <= 90000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:90K-100K'] = np.where((df_inputs_prepr['annual_inc'] > 90000) & (df_inputs_prepr['annual_inc'] <= 100000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:100K-120K'] = np.where((df_inputs_prepr['annual_inc'] > 100000) & (df_inputs_prepr['annual_inc'] <= 120000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:120K-140K'] = np.where((df_inputs_prepr['annual_inc'] > 120000) & (df_inputs_prepr['annual_inc'] <= 140000), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3226331627.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['annual_inc:>140K'] = np.where((df_inputs_prepr['annual_inc'] > 140000), 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# WoE is monotonically decreasing with income, so we split income in 10 equal categories, each with width of 15k.\n",
    "df_inputs_prepr['annual_inc:<20K'] = np.where((df_inputs_prepr['annual_inc'] <= 20000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:20K-30K'] = np.where((df_inputs_prepr['annual_inc'] > 20000) & (df_inputs_prepr['annual_inc'] <= 30000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:30K-40K'] = np.where((df_inputs_prepr['annual_inc'] > 30000) & (df_inputs_prepr['annual_inc'] <= 40000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:40K-50K'] = np.where((df_inputs_prepr['annual_inc'] > 40000) & (df_inputs_prepr['annual_inc'] <= 50000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:50K-60K'] = np.where((df_inputs_prepr['annual_inc'] > 50000) & (df_inputs_prepr['annual_inc'] <= 60000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:60K-70K'] = np.where((df_inputs_prepr['annual_inc'] > 60000) & (df_inputs_prepr['annual_inc'] <= 70000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:70K-80K'] = np.where((df_inputs_prepr['annual_inc'] > 70000) & (df_inputs_prepr['annual_inc'] <= 80000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:80K-90K'] = np.where((df_inputs_prepr['annual_inc'] > 80000) & (df_inputs_prepr['annual_inc'] <= 90000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:90K-100K'] = np.where((df_inputs_prepr['annual_inc'] > 90000) & (df_inputs_prepr['annual_inc'] <= 100000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:100K-120K'] = np.where((df_inputs_prepr['annual_inc'] > 100000) & (df_inputs_prepr['annual_inc'] <= 120000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:120K-140K'] = np.where((df_inputs_prepr['annual_inc'] > 120000) & (df_inputs_prepr['annual_inc'] <= 140000), 1, 0)\n",
    "df_inputs_prepr['annual_inc:>140K'] = np.where((df_inputs_prepr['annual_inc'] > 140000), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Variable: mths_since_last_delinq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   43091\n",
       "mean       34\n",
       "std        22\n",
       "min         0\n",
       "25%        16\n",
       "50%        31\n",
       "75%        50\n",
       "max       170\n",
       "Name: mths_since_last_delinq, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['mths_since_last_delinq'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3027348274.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr_temp['mths_since_last_delinq_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_delinq'], 50)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3027348274.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_inputs_prepr_temp['mths_since_last_delinq_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_delinq'], 50)\n"
     ]
    }
   ],
   "source": [
    "# mths_since_last_delinq\n",
    "# We have to create one category for missing values and do fine and coarse classing for the rest.\n",
    "df_inputs_prepr_temp = df_inputs_prepr[pd.notnull(df_inputs_prepr['mths_since_last_delinq'])]\n",
    "df_inputs_prepr_temp['mths_since_last_delinq_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_delinq'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3878719826.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_delinq:Missing'] = np.where((df_inputs_prepr['mths_since_last_delinq'].isnull()), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3878719826.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_delinq:0-3'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 0) & (df_inputs_prepr['mths_since_last_delinq'] <= 3), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3878719826.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_delinq:4-30'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 4) & (df_inputs_prepr['mths_since_last_delinq'] <= 30), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3878719826.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_delinq:31-56'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 31) & (df_inputs_prepr['mths_since_last_delinq'] <= 56), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/3878719826.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_delinq:>=57'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 57), 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# Categories: Missing, 0-3, 4-30, 31-56, >=57\n",
    "df_inputs_prepr['mths_since_last_delinq:Missing'] = np.where((df_inputs_prepr['mths_since_last_delinq'].isnull()), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:0-3'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 0) & (df_inputs_prepr['mths_since_last_delinq'] <= 3), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:4-30'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 4) & (df_inputs_prepr['mths_since_last_delinq'] <= 30), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:31-56'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 31) & (df_inputs_prepr['mths_since_last_delinq'] <= 56), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_delinq:>=57'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 57), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Variable: DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   93257\n",
       "mean       17\n",
       "std         8\n",
       "min         0\n",
       "25%        11\n",
       "50%        17\n",
       "75%        23\n",
       "max        40\n",
       "Name: dti, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['dti'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/1328348199.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['dti_factor'] = pd.cut(df_inputs_prepr['dti'], 100)\n"
     ]
    }
   ],
   "source": [
    "# dti\n",
    "df_inputs_prepr['dti_factor'] = pd.cut(df_inputs_prepr['dti'], 100)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 100 categories by its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly to income, initial examination shows that most values are lower than 200.\n",
    "# Hence, we are going to have one category for more than 35, and we are going to apply our approach to determine\n",
    "# the categories of everyone with 150k or less.\n",
    "df_inputs_prepr_temp = df_inputs_prepr.loc[df_inputs_prepr['dti'] <= 35, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/2236882563.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_inputs_prepr_temp['dti_factor'] = pd.cut(df_inputs_prepr_temp['dti'], 50)\n"
     ]
    }
   ],
   "source": [
    "df_inputs_prepr_temp['dti_factor'] = pd.cut(df_inputs_prepr_temp['dti'], 50)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/284476014.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['dti:<=1.4'] = np.where((df_inputs_prepr['dti'] <= 1.4), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/284476014.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['dti:1.4-3.5'] = np.where((df_inputs_prepr['dti'] > 1.4) & (df_inputs_prepr['dti'] <= 3.5), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/284476014.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['dti:3.5-7.7'] = np.where((df_inputs_prepr['dti'] > 3.5) & (df_inputs_prepr['dti'] <= 7.7), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/284476014.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['dti:7.7-10.5'] = np.where((df_inputs_prepr['dti'] > 7.7) & (df_inputs_prepr['dti'] <= 10.5), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/284476014.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['dti:10.5-16.1'] = np.where((df_inputs_prepr['dti'] > 10.5) & (df_inputs_prepr['dti'] <= 16.1), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/284476014.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['dti:16.1-20.3'] = np.where((df_inputs_prepr['dti'] > 16.1) & (df_inputs_prepr['dti'] <= 20.3), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/284476014.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['dti:20.3-21.7'] = np.where((df_inputs_prepr['dti'] > 20.3) & (df_inputs_prepr['dti'] <= 21.7), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/284476014.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['dti:21.7-22.4'] = np.where((df_inputs_prepr['dti'] > 21.7) & (df_inputs_prepr['dti'] <= 22.4), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/284476014.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['dti:22.4-35'] = np.where((df_inputs_prepr['dti'] > 22.4) & (df_inputs_prepr['dti'] <= 35), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/284476014.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['dti:>35'] = np.where((df_inputs_prepr['dti'] > 35), 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# Categories:\n",
    "df_inputs_prepr['dti:<=1.4'] = np.where((df_inputs_prepr['dti'] <= 1.4), 1, 0)\n",
    "df_inputs_prepr['dti:1.4-3.5'] = np.where((df_inputs_prepr['dti'] > 1.4) & (df_inputs_prepr['dti'] <= 3.5), 1, 0)\n",
    "df_inputs_prepr['dti:3.5-7.7'] = np.where((df_inputs_prepr['dti'] > 3.5) & (df_inputs_prepr['dti'] <= 7.7), 1, 0)\n",
    "df_inputs_prepr['dti:7.7-10.5'] = np.where((df_inputs_prepr['dti'] > 7.7) & (df_inputs_prepr['dti'] <= 10.5), 1, 0)\n",
    "df_inputs_prepr['dti:10.5-16.1'] = np.where((df_inputs_prepr['dti'] > 10.5) & (df_inputs_prepr['dti'] <= 16.1), 1, 0)\n",
    "df_inputs_prepr['dti:16.1-20.3'] = np.where((df_inputs_prepr['dti'] > 16.1) & (df_inputs_prepr['dti'] <= 20.3), 1, 0)\n",
    "df_inputs_prepr['dti:20.3-21.7'] = np.where((df_inputs_prepr['dti'] > 20.3) & (df_inputs_prepr['dti'] <= 21.7), 1, 0)\n",
    "df_inputs_prepr['dti:21.7-22.4'] = np.where((df_inputs_prepr['dti'] > 21.7) & (df_inputs_prepr['dti'] <= 22.4), 1, 0)\n",
    "df_inputs_prepr['dti:22.4-35'] = np.where((df_inputs_prepr['dti'] > 22.4) & (df_inputs_prepr['dti'] <= 35), 1, 0)\n",
    "df_inputs_prepr['dti:>35'] = np.where((df_inputs_prepr['dti'] > 35), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Variable: mths_since_last_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   12571\n",
       "mean       74\n",
       "std        30\n",
       "min         0\n",
       "25%        53\n",
       "50%        77\n",
       "75%       102\n",
       "max       129\n",
       "Name: mths_since_last_record, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs_prepr['mths_since_last_record'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/2990770712.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr_temp['mths_since_last_record_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_record'], 50)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/2990770712.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_inputs_prepr_temp['mths_since_last_record_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_record'], 50)\n"
     ]
    }
   ],
   "source": [
    "# mths_since_last_record\n",
    "# We have to create one category for missing values and do fine and coarse classing for the rest.\n",
    "df_inputs_prepr_temp = df_inputs_prepr[pd.notnull(df_inputs_prepr['mths_since_last_record'])]\n",
    "#sum(loan_data_temp['mths_since_last_record'].isnull())\n",
    "df_inputs_prepr_temp['mths_since_last_record_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_record'], 50)\n",
    "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/1059239224.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_record:Missing'] = np.where((df_inputs_prepr['mths_since_last_record'].isnull()), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/1059239224.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_record:0-2'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 0) & (df_inputs_prepr['mths_since_last_record'] <= 2), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/1059239224.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_record:3-20'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 3) & (df_inputs_prepr['mths_since_last_record'] <= 20), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/1059239224.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_record:21-31'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 21) & (df_inputs_prepr['mths_since_last_record'] <= 31), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/1059239224.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_record:32-80'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 32) & (df_inputs_prepr['mths_since_last_record'] <= 80), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/1059239224.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_record:81-86'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 81) & (df_inputs_prepr['mths_since_last_record'] <= 86), 1, 0)\n",
      "/var/folders/jm/4cmln_kj5c3fzg5f9mkf28s40000gn/T/ipykernel_1832/1059239224.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_inputs_prepr['mths_since_last_record:>86'] = np.where((df_inputs_prepr['mths_since_last_record'] > 86), 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# Categories: 'Missing', '0-2', '3-20', '21-31', '32-80', '81-86', '>86'\n",
    "df_inputs_prepr['mths_since_last_record:Missing'] = np.where((df_inputs_prepr['mths_since_last_record'].isnull()), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:0-2'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 0) & (df_inputs_prepr['mths_since_last_record'] <= 2), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:3-20'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 3) & (df_inputs_prepr['mths_since_last_record'] <= 20), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:21-31'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 21) & (df_inputs_prepr['mths_since_last_record'] <= 31), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:32-80'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 32) & (df_inputs_prepr['mths_since_last_record'] <= 80), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:81-86'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 81) & (df_inputs_prepr['mths_since_last_record'] <= 86), 1, 0)\n",
    "df_inputs_prepr['mths_since_last_record:>86'] = np.where((df_inputs_prepr['mths_since_last_record'] > 86), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Preprocessed Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_test = df_inputs_prepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_targets_test = df_targets_prepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_inputs_test.to_pickle('../loan_data_inputs_test.pkl')\n",
    "loan_data_targets_test.to_pickle('../loan_data_targets_test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creditEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
